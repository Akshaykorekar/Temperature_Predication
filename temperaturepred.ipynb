{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardized temperature prediction based on history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll be using a LSTM NN to predict the temperature based on past observations. For this purpose, the steps followed are:\n",
    "\n",
    "1. Downsampling of the measurements to 1 every 12 hours\n",
    "2. Normalization of both feature and target variables\n",
    "3. Usage of the last 100 entries (120 hours, 5 days) to predict the next 50 entries (60 hours, 2.5 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#!python -m pip install seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import statsmodels as st\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from the station 14578001 as training data, and data form the station 22005003 as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "WEATHER_STA = 14578001\n",
    "TEST_WEATHER_STA = 22005003\n",
    "\n",
    "def normalize(dataset, target, single_param=False):\n",
    "    if single_param:\n",
    "        dataNorm = dataset\n",
    "        dataNorm[target]=((dataset[target]-dataset[target].min())/(dataset[target].max()-dataset[target].min()))\n",
    "        return dataNorm\n",
    "    else:\n",
    "        dataNorm=((dataset-dataset.min())/(dataset.max()-dataset.min()))\n",
    "#         dataNorm[target]=dataset[target]\n",
    "        return dataNorm\n",
    "\n",
    "def segment(dataset, variable, window = 5000, future = 0):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        start_index = i\n",
    "        end_index = i + window\n",
    "        future_index = i + window + future\n",
    "        if future_index >= len(dataset):\n",
    "            break\n",
    "        data.append(dataset[variable][i:end_index])\n",
    "        labels.append(dataset[variable][end_index:future_index])\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def create_time_steps(length):\n",
    "    return list(range(-length, 0))\n",
    "\n",
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "\n",
    "    plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
    "    plt.plot(np.arange(num_out), np.array(true_future), label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out), np.array(prediction), 'ro', label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016 = pd.read_csv('/home/akshay/Documents/trial/Final Projects/NW_Ground_Stations/NW_Ground_Stations_2016.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-530d0576bb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2017\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/akshay/Documents/trial/Final Projects/NW_Ground_Stations/NW_Ground_Stations_2017.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df2017 = pd.read_csv('/home/akshay/Documents/trial/Final Projects/NW_Ground_Stations/NW_Ground_Stations_2017.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018 = pd.read_csv('/home/akshay/Documents/trial/Final Projects/NW_Ground_Stations/NW_Ground_Stations_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = df2016[(df2016['number_sta'] == WEATHER_STA)]\n",
    "weather = weather.append(df2017[(df2017['number_sta'] == WEATHER_STA)], ignore_index=True)\n",
    "weather = weather.append(df2018[(df2018['number_sta'] == WEATHER_STA)], ignore_index=True)\n",
    "weather['date'] = pd.to_datetime(weather['date'], format='%Y%m%d %H:%M')\n",
    "weather.set_index('date', inplace=True)\n",
    "weather['td'] = weather['td'].interpolate('linear')\n",
    "weather['precip'] = weather['precip'].interpolate('linear')\n",
    "weather['hu'] = weather['hu'].interpolate('linear')\n",
    "weather['ff'] = weather['ff'].interpolate('linear')\n",
    "weather = weather.drop(['number_sta', 'lat', 'lon', 'height_sta'], axis = 1)\n",
    "\n",
    "weather_test = df2016[(df2016['number_sta'] == TEST_WEATHER_STA)]\n",
    "weather_test = weather_test.append(df2017[(df2017['number_sta'] == TEST_WEATHER_STA)], ignore_index=True)\n",
    "weather_test = weather_test.append(df2018[(df2018['number_sta'] == TEST_WEATHER_STA)], ignore_index=True)\n",
    "weather_test['date'] = pd.to_datetime(weather_test['date'], format='%Y%m%d %H:%M')\n",
    "weather_test.set_index('date', inplace=True)\n",
    "weather_test['td'] = weather_test['td'].interpolate('linear')\n",
    "weather_test['precip'] = weather_test['precip'].interpolate('linear')\n",
    "weather_test['hu'] = weather_test['hu'].interpolate('linear')\n",
    "weather_test['ff'] = weather_test['ff'].interpolate('linear')\n",
    "weather_test = weather_test.drop(['number_sta', 'lat', 'lon', 'height_sta'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = normalize(weather, 'td', single_param=False)\n",
    "weather_test = normalize(weather_test, 'td', single_param=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_ds = weather.resample('720T').mean()\n",
    "weather_test_ds = weather_test.resample('720T').mean()\n",
    "\n",
    "weather_ds = weather_ds.fillna(method='bfill')\n",
    "weather_test_ds = weather_ds.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_LAG = 100\n",
    "FUTURE_TARGET = 50\n",
    "\n",
    "X_train, y_train = segment(weather_ds, \"td\", window = HISTORY_LAG, future = FUTURE_TARGET)\n",
    "X_train = X_train.reshape(X_train.shape[0], HISTORY_LAG, 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], FUTURE_TARGET, 1)\n",
    "print(\"Data shape: \", X_train.shape)\n",
    "print(\"Tags shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = segment(weather_test_ds, \"td\", window = HISTORY_LAG, future = FUTURE_TARGET)\n",
    "X_test = X_test.reshape(X_test.shape[0], HISTORY_LAG, 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], FUTURE_TARGET, 1)\n",
    "print(\"Data shape: \", X_test.shape)\n",
    "print(\"Tags shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(HISTORY_LAG, input_shape=X_train.shape[-2:]),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(50),\n",
    "    tf.keras.layers.Dense(FUTURE_TARGET)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', metrics=['mae'], loss='mse')\n",
    "lstm_model.fit(X_train, y_train, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = lstm_model.predict(X_test, verbose=0)\n",
    "y_test = y_test.reshape(y_test.shape[0], FUTURE_TARGET,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the network and used it to predict temperatures using data from the 22005003 station, we can check the results. In the first graph, we well see how would it look if we took every 40th prediction from every 100-long-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "val_final_list = []\n",
    "\n",
    "for i in yPred:\n",
    "    final_list.append(i[40])\n",
    "\n",
    "narray = np.array(final_list)\n",
    "print(narray.shape)\n",
    "\n",
    "for i in y_test:\n",
    "    val_final_list.append(i[40])\n",
    "    \n",
    "val_narray = np.array(val_final_list)\n",
    "print(val_narray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,5))\n",
    "sns.set(rc={\"lines.linewidth\": 3})\n",
    "sns.lineplot(x=np.arange(val_narray.shape[0]), y=val_narray, color=\"green\")\n",
    "sns.set(rc={\"lines.linewidth\": 3})\n",
    "sns.lineplot(x=np.arange(narray.shape[0]), y=narray, color=\"coral\")\n",
    "plt.margins(x=0, y=0.5)\n",
    "plt.legend([\"Original\", \"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can check the result of a random prediction (for example, the 1336th set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_plot(X_test[1336], y_test[1336], yPred[1336])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
